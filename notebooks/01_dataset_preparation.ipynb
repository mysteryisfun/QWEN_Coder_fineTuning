{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc97c24",
   "metadata": {},
   "source": [
    "# Dataset Preparation: CodeRM-UnitTest Loading and Splitting\n",
    "\n",
    "This notebook handles Step 2 of our masterplan:\n",
    "- Load CodeRM-UnitTest dataset from Hugging Face\n",
    "- Explore dataset structure and understand the format\n",
    "- Sample 20k records from the full 77.2k dataset\n",
    "- Create 80/10/10 split (16k train / 2k val / 2k test)\n",
    "- Save preprocessed splits locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d461bc6a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f7c35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 14:50:39,426 - INFO - Starting dataset preparation process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('../logs/dataset_preparation.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "logger.info(\"Starting dataset preparation process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38166b9d",
   "metadata": {},
   "source": [
    "## 2. Setup Environment and GPU Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d97f5d",
   "metadata": {},
   "source": [
    "### GPU Setup Troubleshooting\n",
    "\n",
    "If GPU is not detected, run this cell to install PyTorch with CUDA support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa88d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch and CUDA Diagnostics ===\n",
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 90100\n",
      "Number of GPUs: 1\n",
      "CUDA built with PyTorch: True\n",
      "\n",
      "Device selected: cuda\n",
      "\n",
      "=== GPU Information ===\n",
      "GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "  Total memory: 4.00 GB\n",
      "  Major.Minor: 8.6\n",
      "  Multi-processor count: 16\n",
      "\n",
      "=== GPU Memory Status ===\n",
      "Total GPU Memory: 4.00 GB\n",
      "Reserved Memory: 0.00 GB\n",
      "Allocated Memory: 0.00 GB\n",
      "Free Memory: 4.00 GB\n",
      "‚úÖ GPU test successful - tensor shape: torch.Size([100, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 14:53:05,037 - INFO - GPU detected and tested: NVIDIA GeForce RTX 3050 Laptop GPU with 4.00 GB memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Directory structure verified\n",
      "Final device for training: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Comprehensive GPU and CUDA diagnostics\n",
    "print(\"=== PyTorch and CUDA Diagnostics ===\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Check if CUDA is built with PyTorch\n",
    "if hasattr(torch.cuda, 'is_available'):\n",
    "    print(f\"CUDA built with PyTorch: {torch.cuda.is_available()}\")\n",
    "else:\n",
    "    print(\"CUDA not built with PyTorch\")\n",
    "\n",
    "# Device detection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nDevice selected: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n=== GPU Information ===\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}\")\n",
    "        print(f\"  Total memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  Major.Minor: {props.major}.{props.minor}\")\n",
    "        print(f\"  Multi-processor count: {props.multi_processor_count}\")\n",
    "    \n",
    "    # Set to first GPU and get detailed memory info\n",
    "    torch.cuda.set_device(0)\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    gpu_memory_free = gpu_memory_total - gpu_memory_allocated\n",
    "    \n",
    "    print(f\"\\n=== GPU Memory Status ===\")\n",
    "    print(f\"Total GPU Memory: {gpu_memory_total:.2f} GB\")\n",
    "    print(f\"Reserved Memory: {gpu_memory_reserved:.2f} GB\")\n",
    "    print(f\"Allocated Memory: {gpu_memory_allocated:.2f} GB\")\n",
    "    print(f\"Free Memory: {gpu_memory_free:.2f} GB\")\n",
    "    \n",
    "    # Test GPU with a simple operation\n",
    "    try:\n",
    "        test_tensor = torch.randn(100, 100).to(device)\n",
    "        result = torch.matmul(test_tensor, test_tensor)\n",
    "        print(f\"‚úÖ GPU test successful - tensor shape: {result.shape}\")\n",
    "        del test_tensor, result\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GPU test failed: {e}\")\n",
    "    \n",
    "    logger.info(f\"GPU detected and tested: {torch.cuda.get_device_name(0)} with {gpu_memory_total:.2f} GB memory\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No GPU available or CUDA not properly installed\")\n",
    "    print(\"Possible solutions:\")\n",
    "    print(\"1. Install CUDA-enabled PyTorch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "    print(\"2. Check NVIDIA drivers are installed\")\n",
    "    print(\"3. Verify CUDA toolkit is installed\")\n",
    "    \n",
    "    # Check NVIDIA driver\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, shell=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n‚úÖ NVIDIA drivers detected:\")\n",
    "            print(result.stdout.split('\\n')[0])  # First line with driver info\n",
    "        else:\n",
    "            print(\"\\n‚ùå NVIDIA drivers not found or nvidia-smi not available\")\n",
    "    except:\n",
    "        print(\"\\n‚ùå Could not check NVIDIA drivers\")\n",
    "    \n",
    "    logger.warning(\"No GPU available, training will use CPU (this will be very slow)\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../logs', exist_ok=True)\n",
    "print(f\"\\n‚úÖ Directory structure verified\")\n",
    "print(f\"Final device for training: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711b65a",
   "metadata": {},
   "source": [
    "## 3. Load CodeRM-UnitTest Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495b5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 14:53:26,329 - INFO - Loading CodeRM-UnitTest dataset from Hugging Face\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6828e13866994130b49605624d554875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ujwal\\anaconda3\\envs\\finetune\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ujwal\\.cache\\huggingface\\hub\\datasets--KAKA22--CodeRM-UnitTest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-08-21 14:53:32,066 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dc856e803149d5891f11f0739651f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unit_test_taco-train.parquet:   0%|          | 0.00/509M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-08-21 14:53:59,642 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a501defff6405db25788181e392120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unit_test_codefeedback-filter.parquet:   0%|          | 0.00/778M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1214e05a79ec441daf863f322dacb204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b1790cddab41448711ec91b030c4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 14:57:16,396 - INFO - Dataset loaded with 17562 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['task_id', 'question', 'code_ground_truth', 'code_generate', 'unit_tests'],\n",
      "        num_rows: 17562\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['task_id', 'question', 'code_ground_truth', 'code_generate', 'unit_tests'],\n",
      "        num_rows: 62900\n",
      "    })\n",
      "})\n",
      "Total samples in dataset: 17562\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "logger.info(\"Loading CodeRM-UnitTest dataset from Hugging Face\")\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(\"KAKA22/CodeRM-UnitTest\")\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Dataset structure: {dataset}\")\n",
    "    \n",
    "    # Get the train split (assuming it's the main split)\n",
    "    train_data = dataset['train']\n",
    "    print(f\"Total samples in dataset: {len(train_data)}\")\n",
    "    \n",
    "    logger.info(f\"Dataset loaded with {len(train_data)} samples\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading dataset: {str(e)}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94734e24",
   "metadata": {},
   "source": [
    "## 4. Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9102f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 14:57:27,122 - INFO - Dataset structure exploration completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Features ===\n",
      "{'task_id': Value('int64'), 'question': Value('string'), 'code_ground_truth': Value('string'), 'code_generate': Value('string'), 'unit_tests': Value('string')}\n",
      "\n",
      "=== First Sample ===\n",
      "task_id: 0\n",
      "question: There are $n$ candy boxes in front of Tania. The boxes are arranged in a row from left to right, numbered from $1$ to $n$. The $i$-th box contains $r_i$ candies, candies have the color $c_i$ (the colo...\n",
      "code_ground_truth: def min_seconds_to_eat_candies(n, s, k, r, c):\n",
      "    INF = 10000000000.0\n",
      "    max_n = 50\n",
      "    max_k = 2000\n",
      "    \n",
      "    s -= 1  # Convert to 0-based index\n",
      "    buf = [''] * (max_n + 1)\n",
      "    dp = [[0 for _ in ra...\n",
      "code_generate: [{\"sol_id\": 0, \"code\": \"def min_seconds_to_eat_candies(n, s, k, r, c):\\n    \\\"\\\"\\\"\\n    This function calculates the minimum number of seconds Tanya needs to eat at least k candies.\\n    \\n    Paramet...\n",
      "unit_tests: [{\"ut_id\": 0, \"code\": \"import unittest\\n\\nclass TestMinSecondsToEatCandies(unittest.TestCase):\\n    \\n    def test_example1(self):\\n        # Test the first example in the problem statement\\n        n...\n"
     ]
    }
   ],
   "source": [
    "# Examine the first few samples\n",
    "print(\"=== Dataset Features ===\")\n",
    "print(train_data.features)\n",
    "\n",
    "print(\"\\n=== First Sample ===\")\n",
    "first_sample = train_data[0]\n",
    "for key, value in first_sample.items():\n",
    "    if isinstance(value, str) and len(value) > 200:\n",
    "        print(f\"{key}: {value[:200]}...\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "logger.info(\"Dataset structure exploration completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327552cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unit Tests Structure ===\n",
      "Type of unit_tests: <class 'str'>\n",
      "Number of unit tests for first sample: 189276\n",
      "\n",
      "=== First Unit Test ===\n",
      "Type of first test: <class 'str'>\n",
      "Unit test content: [...\n",
      "\n",
      "=== Quality Metrics Analysis ===\n",
      "Sample test type: <class 'str'>\n",
      "Unit tests are stored as strings, not dictionaries with FAR/FRR metrics\n",
      "This means the dataset structure is different than expected\n"
     ]
    }
   ],
   "source": [
    "# Examine unit tests structure\n",
    "print(\"=== Unit Tests Structure ===\")\n",
    "if 'unit_tests' in first_sample:\n",
    "    unit_tests = first_sample['unit_tests']\n",
    "    print(f\"Type of unit_tests: {type(unit_tests)}\")\n",
    "    print(f\"Number of unit tests for first sample: {len(unit_tests)}\")\n",
    "    \n",
    "    if len(unit_tests) > 0:\n",
    "        print(\"\\n=== First Unit Test ===\")\n",
    "        first_test = unit_tests[0]\n",
    "        print(f\"Type of first test: {type(first_test)}\")\n",
    "        \n",
    "        # Handle if it's a string\n",
    "        if isinstance(first_test, str):\n",
    "            print(f\"Unit test content: {first_test[:500]}...\")  # Show first 500 chars\n",
    "        # Handle if it's a dictionary\n",
    "        elif isinstance(first_test, dict):\n",
    "            for key, value in first_test.items():\n",
    "                if isinstance(value, str) and len(value) > 200:\n",
    "                    print(f\"{key}: {value[:200]}...\")\n",
    "                else:\n",
    "                    print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"Unexpected type: {type(first_test)}\")\n",
    "            print(f\"Content: {first_test}\")\n",
    "\n",
    "# Check data quality metrics - also need to fix this part\n",
    "print(\"\\n=== Quality Metrics Analysis ===\")\n",
    "if 'unit_tests' in first_sample and len(first_sample['unit_tests']) > 0:\n",
    "    # First check what structure we're dealing with\n",
    "    sample_test = first_sample['unit_tests'][0]\n",
    "    print(f\"Sample test type: {type(sample_test)}\")\n",
    "    \n",
    "    if isinstance(sample_test, dict):\n",
    "        # If it's a dictionary, we can access FAR/FRR\n",
    "        far_values = [test.get('FAR', 0) for test in first_sample['unit_tests'] if isinstance(test, dict)]\n",
    "        frr_values = [test.get('FRR', 0) for test in first_sample['unit_tests'] if isinstance(test, dict)]\n",
    "        if far_values and frr_values:\n",
    "            print(f\"FAR range in first sample: {min(far_values):.3f} - {max(far_values):.3f}\")\n",
    "            print(f\"FRR range in first sample: {min(frr_values):.3f} - {max(frr_values):.3f}\")\n",
    "        else:\n",
    "            print(\"No FAR/FRR values found in the unit tests\")\n",
    "    else:\n",
    "        print(\"Unit tests are stored as strings, not dictionaries with FAR/FRR metrics\")\n",
    "        print(\"This means the dataset structure is different than expected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d012be",
   "metadata": {},
   "source": [
    "## 5. Sample 20k Records from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad4b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 15:01:30,149 - INFO - Sampling 20000 records from 17562 total samples\n",
      "2025-08-21 15:01:30,150 - WARNING - Dataset smaller than requested sample size, using all 17562 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has only 17562 samples, using all available data\n",
      "Final dataset size for training: 17562 samples\n"
     ]
    }
   ],
   "source": [
    "# Sample 20k records from the full dataset (or use all if less than 20k)\n",
    "SAMPLE_SIZE = 20000\n",
    "total_samples = len(train_data)\n",
    "\n",
    "logger.info(f\"Sampling {SAMPLE_SIZE} records from {total_samples} total samples\")\n",
    "\n",
    "if total_samples >= SAMPLE_SIZE:\n",
    "    # Use random sampling to get diverse data\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    sample_indices = np.random.choice(total_samples, SAMPLE_SIZE, replace=False)\n",
    "    sample_indices = sorted(sample_indices)  # Sort for efficient access\n",
    "    \n",
    "    sampled_data = train_data.select(sample_indices)\n",
    "    effective_sample_size = SAMPLE_SIZE\n",
    "    print(f\"Successfully sampled {len(sampled_data)} records\")\n",
    "    \n",
    "    logger.info(f\"Sampled {len(sampled_data)} records using random sampling\")\n",
    "else:\n",
    "    print(f\"Dataset has only {total_samples} samples, using all available data\")\n",
    "    sampled_data = train_data\n",
    "    effective_sample_size = total_samples\n",
    "    \n",
    "    logger.warning(f\"Dataset smaller than requested sample size, using all {total_samples} samples\")\n",
    "\n",
    "print(f\"Final dataset size for training: {effective_sample_size} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5bb138",
   "metadata": {},
   "source": [
    "## 6. Create 80/10/10 Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb8b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 15:01:41,923 - INFO - Converting dataset to pandas DataFrame for splitting\n",
      "2025-08-21 15:02:00,277 - INFO - Created splits - Train: 14049, Val: 1756, Test: 1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 17562 samples to list format\n",
      "Data split sizes:\n",
      "Train: 14049 samples (80.0%)\n",
      "Validation: 1756 samples (10.0%)\n",
      "Test: 1757 samples (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Convert to pandas DataFrame for easier splitting\n",
    "logger.info(\"Converting dataset to pandas DataFrame for splitting\")\n",
    "\n",
    "# Convert the sampled data to a list of dictionaries\n",
    "data_list = []\n",
    "for i in range(len(sampled_data)):\n",
    "    sample = sampled_data[i]\n",
    "    data_list.append(sample)\n",
    "\n",
    "print(f\"Converted {len(data_list)} samples to list format\")\n",
    "\n",
    "# Create indices for splitting\n",
    "indices = list(range(len(data_list)))\n",
    "\n",
    "# First split: 80% train, 20% temp (which will become 10% val + 10% test)\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Second split: Split the 20% into 10% val and 10% test\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices, test_size=0.5, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Data split sizes:\")\n",
    "print(f\"Train: {len(train_indices)} samples ({len(train_indices)/len(data_list)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_indices)} samples ({len(val_indices)/len(data_list)*100:.1f}%)\")\n",
    "print(f\"Test: {len(test_indices)} samples ({len(test_indices)/len(data_list)*100:.1f}%)\")\n",
    "\n",
    "logger.info(f\"Created splits - Train: {len(train_indices)}, Val: {len(val_indices)}, Test: {len(test_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02994dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits created successfully!\n",
      "Train split: 14049 samples\n",
      "Validation split: 1756 samples\n",
      "Test split: 1757 samples\n"
     ]
    }
   ],
   "source": [
    "# Create the actual data splits\n",
    "train_split = [data_list[i] for i in train_indices]\n",
    "val_split = [data_list[i] for i in val_indices]\n",
    "test_split = [data_list[i] for i in test_indices]\n",
    "\n",
    "print(\"Data splits created successfully!\")\n",
    "print(f\"Train split: {len(train_split)} samples\")\n",
    "print(f\"Validation split: {len(val_split)} samples\")\n",
    "print(f\"Test split: {len(test_split)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714570a",
   "metadata": {},
   "source": [
    "## 7. Save Preprocessed Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "342cdb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 15:02:20,063 - INFO - Saving data splits to disk\n",
      "2025-08-21 15:02:59,313 - INFO - All data splits and metadata saved to ..\\data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits saved successfully!\n",
      "Metadata saved to ..\\data\\metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save splits using pickle for Python objects\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logger.info(\"Saving data splits to disk\")\n",
    "\n",
    "# Save splits\n",
    "with open(data_dir / 'train_split.pkl', 'wb') as f:\n",
    "    pickle.dump(train_split, f)\n",
    "    \n",
    "with open(data_dir / 'val_split.pkl', 'wb') as f:\n",
    "    pickle.dump(val_split, f)\n",
    "    \n",
    "with open(data_dir / 'test_split.pkl', 'wb') as f:\n",
    "    pickle.dump(test_split, f)\n",
    "\n",
    "print(\"Data splits saved successfully!\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'total_samples': len(data_list),\n",
    "    'train_size': len(train_split),\n",
    "    'val_size': len(val_split),\n",
    "    'test_size': len(test_split),\n",
    "    'sample_size': SAMPLE_SIZE,\n",
    "    'original_dataset_size': total_samples,\n",
    "    'split_ratio': '80/10/10',\n",
    "    'random_seed': 42,\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'dataset_name': 'KAKA22/CodeRM-UnitTest'\n",
    "}\n",
    "\n",
    "with open(data_dir / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Metadata saved to {data_dir / 'metadata.json'}\")\n",
    "logger.info(f\"All data splits and metadata saved to {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74590b02",
   "metadata": {},
   "source": [
    "## 8. Verify Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db2cdeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 15:03:11,246 - INFO - Verifying saved data integrity\n",
      "2025-08-21 15:03:17,258 - INFO - Data integrity verification completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Verification Results ===\n",
      "Train split loaded: 14049 samples\n",
      "Val split loaded: 1756 samples\n",
      "Test split loaded: 1757 samples\n",
      "\n",
      "Metadata:\n",
      "  total_samples: 17562\n",
      "  train_size: 14049\n",
      "  val_size: 1756\n",
      "  test_size: 1757\n",
      "  sample_size: 20000\n",
      "  original_dataset_size: 17562\n",
      "  split_ratio: 80/10/10\n",
      "  random_seed: 42\n",
      "  created_at: 2025-08-21T15:02:59.307437\n",
      "  dataset_name: KAKA22/CodeRM-UnitTest\n",
      "\n",
      "‚úÖ Data integrity verification passed!\n"
     ]
    }
   ],
   "source": [
    "# Verify the saved data by loading it back\n",
    "logger.info(\"Verifying saved data integrity\")\n",
    "\n",
    "try:\n",
    "    # Load splits back\n",
    "    with open(data_dir / 'train_split.pkl', 'rb') as f:\n",
    "        loaded_train = pickle.load(f)\n",
    "        \n",
    "    with open(data_dir / 'val_split.pkl', 'rb') as f:\n",
    "        loaded_val = pickle.load(f)\n",
    "        \n",
    "    with open(data_dir / 'test_split.pkl', 'rb') as f:\n",
    "        loaded_test = pickle.load(f)\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(data_dir / 'metadata.json', 'r') as f:\n",
    "        loaded_metadata = json.load(f)\n",
    "    \n",
    "    print(\"=== Verification Results ===\")\n",
    "    print(f\"Train split loaded: {len(loaded_train)} samples\")\n",
    "    print(f\"Val split loaded: {len(loaded_val)} samples\")\n",
    "    print(f\"Test split loaded: {len(loaded_test)} samples\")\n",
    "    print(f\"\\nMetadata:\")\n",
    "    for key, value in loaded_metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Quick integrity check\n",
    "    assert len(loaded_train) == len(train_split), \"Train split size mismatch\"\n",
    "    assert len(loaded_val) == len(val_split), \"Val split size mismatch\"\n",
    "    assert len(loaded_test) == len(test_split), \"Test split size mismatch\"\n",
    "    \n",
    "    print(\"\\n‚úÖ Data integrity verification passed!\")\n",
    "    logger.info(\"Data integrity verification completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Verification failed: {str(e)}\")\n",
    "    logger.error(f\"Data verification failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7359b",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ac4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 15:03:20,325 - INFO - Dataset preparation completed successfully!\n",
      "2025-08-21 15:03:20,327 - INFO - Ready to proceed with Step 3: Data preprocessing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Preparation Summary ===\n",
      "‚úÖ Loaded CodeRM-UnitTest dataset (17562 total samples)\n",
      "‚úÖ Sampled 17562 records for training\n",
      "‚úÖ Created 80/10/10 splits:\n",
      "   - Train: 14049 samples\n",
      "   - Validation: 1756 samples\n",
      "   - Test: 1757 samples\n",
      "‚úÖ Saved all splits to ..\\data\n",
      "‚úÖ Data integrity verified\n",
      "\n",
      "=== Files Created ===\n",
      "  metadata.json: 0.00 MB\n",
      "  test_split.pkl: 273.70 MB\n",
      "  train_split.pkl: 2197.99 MB\n",
      "  val_split.pkl: 274.79 MB\n",
      "\n",
      "=== Next Steps ===\n",
      "1. ‚úÖ Step 2 Complete: Dataset loading and splitting\n",
      "2. üîÑ Step 3: Data preprocessing and tokenization\n",
      "3. ‚è≥ Step 4: Model loading and configuration\n",
      "4. ‚è≥ Step 5: QLoRA/PEFT setup\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Dataset Preparation Summary ===\")\n",
    "print(f\"‚úÖ Loaded CodeRM-UnitTest dataset ({total_samples} total samples)\")\n",
    "print(f\"‚úÖ Sampled {len(data_list)} records for training\")\n",
    "print(f\"‚úÖ Created 80/10/10 splits:\")\n",
    "print(f\"   - Train: {len(train_split)} samples\")\n",
    "print(f\"   - Validation: {len(val_split)} samples\")\n",
    "print(f\"   - Test: {len(test_split)} samples\")\n",
    "print(f\"‚úÖ Saved all splits to {data_dir}\")\n",
    "print(f\"‚úÖ Data integrity verified\")\n",
    "\n",
    "print(\"\\n=== Files Created ===\")\n",
    "for file_path in data_dir.glob('*'):\n",
    "    file_size = file_path.stat().st_size / 1024 / 1024  # MB\n",
    "    print(f\"  {file_path.name}: {file_size:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== Next Steps ===\")\n",
    "print(\"1. ‚úÖ Step 2 Complete: Dataset loading and splitting\")\n",
    "print(\"2. üîÑ Step 3: Data preprocessing and tokenization\")\n",
    "print(\"3. ‚è≥ Step 4: Model loading and configuration\")\n",
    "print(\"4. ‚è≥ Step 5: QLoRA/PEFT setup\")\n",
    "\n",
    "logger.info(\"Dataset preparation completed successfully!\")\n",
    "logger.info(f\"Ready to proceed with Step 3: Data preprocessing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
